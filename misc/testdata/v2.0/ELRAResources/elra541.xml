<?xml version="1.0" encoding="UTF-8"?>
<resourceInfo xmlns:xslt="http://xml.apache.org/xsltm" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.ilsp.gr/META-XMLSchema" xsi:schemaLocation="http://www.ilsp.gr/META-XMLSchema">
<identificationInfo>
<resourceName lang="English">MEDIA Evaluation Package</resourceName>
<resourceName lang="French">Package d’évaluation MEDIA</resourceName>
<description lang="English">The MEDIA Evaluation Package was produced within the French national project MEDIA (Automatic evaluation of man-machine dialogue systems), as part of the Technolangue programme funded by the French Ministry of Research and New Technologies (MRNT). The MEDIA project enabled to carry out a campaign for the evaluation of man-machine dialogue systems for French. This package includes the material that was used for the MEDIA evaluation campaign. It includes resources, protocols, scoring tools, results of the campaign, etc., that were used or produced during the campaign. The aim of these evaluation packages is to enable external players to evaluate their own system and compare their results with those obtained during the campaign itself. The campaign is distributed over two actions: 1)	Evaluation taking into account the dialogue context: it consists in producing semantic annotation outside dialogue context for each of the 3,000 test prompts.2)	Evaluation not taking into account the dialogue context: it consists in evaluating the capacity of understanding systems a) from orthographic transcriptions only and b) from transcriptions and reference annotations outside dialogue context.The MEDIA evaluation package contains the following data and tools:1)	Corpus of 1,258 dialogues (WoZ) recorded for a tourist information task, with transcriptions and annotations in dialogue acts and in semantic segments within or outside dialogue context. The annotations follow the XML formalism. This corpus consists of 18,831 user prompts used for the adaptation of systems and for evaluation.2)	The text corpus (200 dialogues) is annotated with meta-annotations in order to proceed with a diagnosis study of the systems output. These meta-annotations consist of annotations of speech-oriented phenomena such as repetitions, auto-corrections, incises, etc.3)	The Semantizer annotation tool.4)	The Mediaval HC (outside context) evaluation tool.5)	The Mediaval EC (within context) evaluation tool. A description of the project is available at the following address:http://www.technolangue.net/article.php3?id_article=62 (in French language)</description>
<description lang="French">Le package d’évaluation MEDIA a été produit dans le cadre du projet national français MEDIA (« Méthodologie d'Evaluation automatique de la compréhension hors et en contexte du DIAlogue »), issu du programme Technolangue, financé par le Ministère français délégué à la Recherche et aux Nouvelles Technologies (MRNT). Le projet MEDIA a permis de réaliser une campagne d'évaluation de la compréhension des systèmes de dialogue pour le français.  Ce package comprend l’ensemble des données utilisées lors de la campagne d’évaluation MEDIA. Il regroupe des ressources, des protocoles, des outils de notation, les résultats de la campagne officielle, etc., qui ont été utilisés ou produits pendant la campagne. Le but de ce « package » d’évaluation est de permettre à tout acteur externe de pouvoir évaluer son propre système et ainsi de pouvoir comparer ses résultats à ceux obtenus pendant la campagne.La campagne se décompose en deux tâches: 1)	Evaluation du dialogue hors contexte : consiste à produire l’annotation sémantique hors contexte du dialogue de chacun des 3000 énoncés de test.2)	Evaluation du dialogue en contexte : consiste à évaluer la capacité des systèmes de compréhension a) à partir des transcriptions orthographiques seules et b) à partir des transcriptions et des annotations hors contexte de référence.Le package d’évaluation MEDIA contient les données et outils suivants :1)	Corpus de 1258 dialogues enregistrés (WoZ)  pour la tâche d’informations touristiques, transcrit et annoté en actes de dialogues et en segments sémantiques hors et en contexte de dialogue. Les annotations respectent le formalisme XML. Ce corpus comprend 18 831  énoncés utilisateur utilisés pour l'adaption des systèmes et pour l'évaluation. 2)	Le corpus de test (200 dialogues) est annoté en méta-annotations afin de procéder à une étude diagnostique des sorties des systèmes. Ces méta-annotations comprennent des annotations de phénomènes liés à l’oral telles les répétitions, les auto-corrections, les incises, etc.3)	L’outil d’annotation Semantizer.4)	L’outil d’évaluation Mediaval HC hors contexte.5)	L'outil d'évaluation Mediaval EC en contexte de dialogue .Une description du projet est disponible à l'adresse suivante :http://www.technolangue.net/article.php3?id_article=62</description>
<resourceShortName/>
<url>http://catalog.elra.info/product_info.php?products_id=998</url>
<metaShareId>NOT_DEFINED_FOR_V2</metaShareId>
<identifier>ELRA-E0024</identifier>
</identificationInfo>
<distributionInfo>
<availability>available-restrictedUse</availability>
<licenceInfo>
<licence>ELRA_END_USER</licence>
<restrictionsOfUse>academic-nonCommercialUse</restrictionsOfUse>
<fee>7500.00</fee>
<userNature>commercial</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_EVALUATION</licence>
<restrictionsOfUse>evaluationUse</restrictionsOfUse>
<fee>6500.00</fee>
<userNature>commercial</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_VAR</licence>
<restrictionsOfUse>commercialUse</restrictionsOfUse>
<fee>25000.00</fee>
<userNature>commercial</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_END_USER</licence>
<restrictionsOfUse>academic-nonCommercialUse</restrictionsOfUse>
<fee>2000.00</fee>
<userNature>academic</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_VAR</licence>
<restrictionsOfUse>commercialUse</restrictionsOfUse>
<fee>25000.00</fee>
<userNature>academic</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_END_USER</licence>
<restrictionsOfUse>academic-nonCommercialUse</restrictionsOfUse>
<fee>5000.00</fee>
<userNature>commercial</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_EVALUATION</licence>
<restrictionsOfUse>evaluationUse</restrictionsOfUse>
<fee>1000.00</fee>
<userNature>commercial</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_VAR</licence>
<restrictionsOfUse>commercialUse</restrictionsOfUse>
<fee>20000.00</fee>
<userNature>commercial</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_END_USER</licence>
<restrictionsOfUse>academic-nonCommercialUse</restrictionsOfUse>
<fee>300.00</fee>
<userNature>academic</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_VAR</licence>
<restrictionsOfUse>commercialUse</restrictionsOfUse>
<fee>20000.00</fee>
<userNature>academic</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<availabilityStartDate>2007-06-28</availabilityStartDate>
</distributionInfo>
<contactPerson>
<surname lang="en-us">Valérie</surname>
<givenName lang="en-us">Mapelli</givenName>
<communicationInfo>
<email>mapelli@elda.org</email>
<url>http://www.elda.org</url>
<address>55-57 rue Brillat-Savarin</address>
<zipCode>75013</zipCode>
<city>Paris</city>
<country>France</country>
<telephoneNumber>+1 43 13 33 33</telephoneNumber>
<faxNumber>+1 43 14 33 30</faxNumber>
</communicationInfo>
</contactPerson>
<metadataInfo>
<metadataCreationDate>2005-05-12</metadataCreationDate>
</metadataInfo>
<versionInfo>
<version>1.0</version>
<lastDateUpdated>2007-06-28</lastDateUpdated>
</versionInfo>
<resourceCreationInfo>
<fundingProject>
<projectName>EVALDA</projectName>
<fundingType>nationalFunds</fundingType>
</fundingProject>
</resourceCreationInfo>
<resourceComponentType>
<corpusInfo>
<resourceType>corpus</resourceType>
<corpusMediaType>
<corpusAudioInfo>
<mediaType>audio</mediaType>
<lingualityInfo>
<lingualityType>monolingual</lingualityType>
</lingualityInfo>
<languageInfo>
<languageId>fre/fra</languageId>
<languageName>French</languageName>
</languageInfo>
<audioSizeInfo>
<sizeInfo>
<size>no size available</size>
<sizeUnit>other</sizeUnit>
</sizeInfo>
</audioSizeInfo>
</corpusAudioInfo>
</corpusMediaType>
</corpusInfo>
</resourceComponentType>
</resourceInfo>
