<?xml version="1.0" encoding="UTF-8"?>
<resourceInfo xsi:schemaLocation="http://www.ilsp.gr/META-XMLSchema" xmlns:xslt="http://xml.apache.org/xsltm" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.ilsp.gr/META-XMLSchema">
<identificationInfo>
<resourceName lang="English">Czech Audio-Visual Speech Corpus for Recognition with Impaired Conditions</resourceName>
<resourceName lang="French">Corpus tchèque audio-visuel pour la reconnaissance en conditions difficiles</resourceName>
<description lang="English">This is an audio-visual speech database for training and testing of Czech audio-visual continuous speech recognition systems collected with impaired illumination conditions. The corpus consists of about 20 hours of audio-visual records of 50 speakers in laboratory conditions. Recorded subjects were instructed to remain static. The illumination varied and chunks of each speaker were recorded with several different conditions, such as full illumination, or illumination from one side (left or right) only. These conditions make the database usable for training lip-/head-tracking systems under various illumination conditions independently of the language. Speakers were asked to read 200 sentences each (50 common for all speakers and 150 specific to each speaker). The average total length of recording per speaker was 23 minutes.Acoustic data are stored in wave files using PCM format, sampling frequency 44kHz, resolution 16 bits. Each speaker’s acoustic data set represents about 180 MB of disk space (about 8.8 GB).Visual data are stored in video files (.avi format) using the digital video (DV) codec. Visual data per speaker take about 3.7 GB of disk (about 185 GB as a whole) and are stored on an IDE hard disk (NTFS format).</description>
<description lang="French">Cette base de données audio-visuelle a été constituée pour entraîner et tester les systèmes de reconnaissance audio-visuelle en langue tchèque et a été collectée en conditions d’éclairage difficile. Le corpus comprend environ 20 heures d’enregistrements audio-visuels de 50 locuteurs en conditions de laboratoire. On a demandé aux sujets enregistrés de rester en position statique. L’éclairage est varié et les sessions de chaque locuteur ont été enregistrées dans plusieurs conditions différentes, telles qu’en éclairage total ou seulement en éclairage de côté (gauche ou droite). Ces conditions rendent cette base de données utilisable pour l’entraînement de systèmes de détection des mouvements de lèvres ou de tête dans différentes conditions d’éclairage et indépendamment de la langue.On a demandé aux locuteurs de lire 200 phrases chacun (50 en commun pour tous les locuteurs et 150 spécifiques à chaque locuteur). La durée moyenne totale d’enregistrement par locuteur est de 23 minutes.Les données acoustiques ont été stockées en fichiers wave en utilisant le format PCM, une fréquence d’échantillonnage de 44kHz et une résolution de 16 bits. Un ensemble de données acoustiques pour chaque locuteur représente environ 180 Mo d’espace-disque (environ 8,8 Go en totalité).Les données visuelles sont stockées en fichiers vidéo (format .avi) utilisant le codec vidéo numérique DV. Les données visuelles par locuteur prennent environ 3,7 Go de disque (environ 185 Go en totalité) et sont stockées sur un disque dur IDE au format NTFS.</description>
<resourceShortName>UWB-07-ICAVR I</resourceShortName>
<metaShareId>NOT_DEFINED_FOR_V2</metaShareId>
<url>http://catalog.elra.info/product_info.php?products_id=1082</url>
<identifier>ELRA-S0284</identifier>
</identificationInfo>
<metadataInfo>
<metadataCreationDate>2005-05-12</metadataCreationDate>
<metadataCreator>
<surname lang="en-us">Valérie</surname>
<givenName lang="en-us">Mapelli</givenName>
<communicationInfo>
<email>mapelli@elda.org</email>
<url>http://www.elda.org</url>
<address>55-57 rue Brillat-Savarin</address>
<zipcode>75013</zipcode>
<city>Paris</city>
<country>France</country>
<telephoneNumber>+1 43 13 33 33</telephoneNumber>
<faxNumber>+1 43 14 33 30</faxNumber>
</communicationInfo>
</metadataCreator>
</metadataInfo>
<versionInfo>
<version>1.0</version>
<lastDateUpdated>2008-11-05</lastDateUpdated>
</versionInfo>
<distributionInfo>
<availability>available-restrictedUse</availability>
<licenceInfo>
<licence>ELRA_END_USER</licence>
<restrictionsOfUse>academic-nonCommercialUse</restrictionsOfUse>
<price>Commercial org. ELRA Non Member: 1250.00€</price>
<price>Academic org. ELRA Non Member: 1250.00€</price>
<price>Commercial org. ELRA Member: 650.00€</price>
<price>Academic org. ELRA Member: 650.00€</price>
<availabilityStartDate>2008-11-05</availabilityStartDate>
</licenceInfo>
<licenceInfo>
<licence>ELRA_VAR</licence>
<restrictionsOfUse>commercialUse</restrictionsOfUse>
<price>Commercial org. ELRA Non Member: 4550.00€</price>
<price>Academic org. ELRA Non Member: 4550.00€</price>
<price>Commercial org. ELRA Member: 3050.00€</price>
<price>Academic org. ELRA Member: 3050.00€</price>
<availabilityStartDate>2008-11-05</availabilityStartDate>
</licenceInfo>
</distributionInfo>
<usageInfo>
<actualUseInfo>
<actualUse>nlpApplications</actualUse>
<useNLPSpecific>speechRecognition</useNLPSpecific>
</actualUseInfo>
</usageInfo>
<resourceComponentType>
<corpusInfo>
<resourceType>corpus</resourceType>
<corpusMediaType>
<corpusAudioInfo>
<mediaType>audio</mediaType>
<lingualityInfo>
<lingualityType>monolingual</lingualityType>
</lingualityInfo>
<languageInfo>
<languageId>cze/ces</languageId>
<languageName>Czech</languageName>
</languageInfo>
</corpusAudioInfo>
<corpusVideoInfo>
<mediaType>video</mediaType>
<lingualityInfo>
<lingualityType>monolingual</lingualityType>
</lingualityInfo>
<languageInfo>
<languageId>cze/ces</languageId>
<languageName>Czech</languageName>
</languageInfo>
</corpusVideoInfo>
</corpusMediaType>
</corpusInfo>
</resourceComponentType>
</resourceInfo>
