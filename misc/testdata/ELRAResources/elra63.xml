<?xml version="1.0" encoding="UTF-8"?>
<resourceInfo xmlns:xslt="http://xml.apache.org/xsltm" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.ilsp.gr/META-XMLSchema" xsi:schemaLocation="http://www.ilsp.gr/META-XMLSchema">
<identificationInfo>
<resourceName lang="English">TC-STAR 2005 Evaluation Package - ASR Spanish</resourceName>
<resourceName lang="French">Package d’évaluation TC-STAR 2005 - ASR espagnol</resourceName>
<description lang="English">TC-STAR is a European integrated project focusing on Speech-to-Speech Translation (SST). To encourage significant breakthrough in all SST technologies, annual open competitive evaluations are organized. Automatic Speech Recognition (ASR), Spoken Language Translation (SLT) and Text-To-Speech (TTS) are evaluated independently and within an end-to-end system.The first TC-STAR evaluation campaign took place in March 2005. Two core technologies were evaluated during the campaign:• Automatic Speech Recognition (ASR),• Spoken Language Translation (SLT).Each evaluation package includes resources, protocols, scoring tools, results of the official campaign, etc., that were used or produced during the first evaluation campaign. The aim of these evaluation packages is to enable external players to evaluate their own system and compare their results with those obtained during the campaign itself.The speech databases made within the TC-STAR project were validated by SPEX, in the Netherlands, to assess their compliance with the TC-STAR format and content specifications.This package includes the material used for the TC-STAR 2005 Automatic Speech Recognition (ASR) first evaluation campaign for the Spanish language. The same packages are available for both English (ELRA-E0002) and Mandarin (ELRA-E0004) for ASR and for SLT in 3 directions, English-to-Spanish (ELRA-E0005), Spanish-to-English (ELRA-E0006), Chinese-to-English (ELRA-E0007).To be able to chain the components, ASR and SLT evaluation tasks were designed to use common sets of raw data and conditions. Two evaluation tasks, common to ASR and SLT, were selected: EPPS (European Parliament Plenary Sessions) task and VOA (Voice of America) task. This package was used within the EPPS task and consists of 2 data sets:- Development data set: consists of audio recordings of Parliament’s sessions from 25 to 28 October 2004, manually transcribed. 3.75 hours of recordings were selected and transcribed, corresponding to approximately 33,000 running words in Spanish.- Test data set: consists of audio recordings of Parliament’s sessions from 15 to 18 November 2004. As for the development set, the test data set is made of 3.75 hours (33,000 running words).</description>
<description lang="French">TC-STAR est un projet intégré européen basé sur la traduction parole-parole (ou SST pour Speech-to-Speech Translation). Pour encourager de manière conséquente l’avancée dans toutes les technologies de la SST, des évaluations ouvertes à la concurrence sont organisées sur une base annuelle. Les technologies de la reconnaissance automatique de la parole (ou ASR pour « Automatic Speech Recognition »), de la traduction de la langue parlée (ou SLT pour « Spoken Language Translation ») et les technologies texte-parole (ou TTS pour « Text-to-Speech ») sont évaluées à la fois de façon indépendante et intégrée à un système « end-to-end » (de « bout en bout »).La première campagne d’évaluation TC-STAR s’est déroulée en mars 2005. Deux technologies de base ont été évaluées lors de cette campagne:• la reconnaissance automatique de la parole (ASR),• la traduction de la langue parlée (SLT).Chaque package d’évaluation regroupe des ressources, des protocoles, des outils de notation, les résultats de la campagne officielle, etc., qui ont été utilisés ou produits pendant la première campagne d’évaluation. Le but de ces packages d’évaluation est de permettre à des acteurs externes d’évaluer leur propre système et de comparer leurs résultats à ceux obtenus pendant la campagne.Les bases de données orales produites dans le projet TC-STAR ont été validées par SPEX, Pays-Bas, selon le format et les spécifications de contenu TC-STAR.Ce package comprend le matériel utilisé pour la première campagne d’évaluation TC-STAR 2005 Automatic Speech Recognition (ASR) pour l’espagnol. Des packages similaires sont également disponibles pour l’anglais (ELRA-E0002) et le chinois mandarin (ELRA-E0004) pour l’ASR, ainsi que pour la SLT dans 3 sens, anglais vers espagnol (ELRA-E0005), espagnol vers anglais (ELRA-E0006), chinois vers anglais (ELRA-E0007).Pour permettre de regrouper les composants, les tâches d’évaluation ASR et SLT ont été conçues en utilisant des données brutes et des conditions communes. Deux tâches d’évaluation, communes à l’ASR et à la SLT, ont été choisies : la tâche EPPS (« European Parliament Plenary Sessions » – Sessions plénières du Parlement européen) et la tâche VOA (« Voice of America » - La voix de l’Amérique). Le présent package a été utilisé dans le cadre de la tâche EPPS et comprend 2 ensembles de données :- L’ensemble de données de développement : il comprend les enregistrements audio des sessions du Parlement du 25 au 28 octobre 2004, transcrites manuellement. Environ 3,75 heures d’enregistrements ont été choisies et transcrites, et correspondent à environ 33 000 mots courants de l’espagnol.- L’ensemble de données de test : il comprend les enregistrements audio des sessions du Parlement du 15 au 18 novembre 2004. Comme pour l’ensemble de développement, les données de test comprennent 3,75 heures d’enregistrements (33 000 mots courants).</description>
<resourceShortName/>
<url>http://catalog.elra.info/product_info.php?products_id=849</url>
<metaShareId>NOT_DEFINED_FOR_V2</metaShareId>
<identifier>ELRA-E0003</identifier>
</identificationInfo>
<distributionInfo>
<availability>available-restrictedUse</availability>
<licenceInfo>
<licence>ELRA_EVALUATION</licence>
<restrictionsOfUse>evaluationUse</restrictionsOfUse>
<price>750.00</price>
<userNature>commercial</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_EVALUATION</licence>
<restrictionsOfUse>evaluationUse</restrictionsOfUse>
<price>750.00</price>
<userNature>academic</userNature>
<membershipInfo>
<member>false</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_EVALUATION</licence>
<restrictionsOfUse>evaluationUse</restrictionsOfUse>
<price>500.00</price>
<userNature>commercial</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<licenceInfo>
<licence>ELRA_EVALUATION</licence>
<restrictionsOfUse>evaluationUse</restrictionsOfUse>
<price>500.00</price>
<userNature>academic</userNature>
<membershipInfo>
<member>true</member>
<membershipInstitution>ELRA</membershipInstitution>
</membershipInfo>
</licenceInfo>
<availabilityStartDate>2006-03-22</availabilityStartDate>
</distributionInfo>
<contactPerson>
<surname lang="en-us">Valérie</surname>
<givenName lang="en-us">Mapelli</givenName>
<communicationInfo>
<email>mapelli@elda.org</email>
<url>http://www.elda.org</url>
<address>55-57 rue Brillat-Savarin</address>
<zipCode>75013</zipCode>
<city>Paris</city>
<country>France</country>
<telephoneNumber>+1 43 13 33 33</telephoneNumber>
<faxNumber>+1 43 14 33 30</faxNumber>
</communicationInfo>
</contactPerson>
<metadataInfo>
<metadataCreationDate>2005-05-12</metadataCreationDate>
</metadataInfo>
<versionInfo>
<version>1.0</version>
<lastDateUpdated>2007-03-27</lastDateUpdated>
</versionInfo>
<usageInfo>
<actualUseInfo>
<actualUse>nlpApplications</actualUse>
<useNLPSpecific>speechRecognition</useNLPSpecific>
</actualUseInfo>
</usageInfo>
<resourceCreationInfo>
<fundingProject>
<projectName>TC-STAR</projectName>
<fundingType>euFunds</fundingType>
</fundingProject>
</resourceCreationInfo>
<resourceComponentType>
<corpusInfo>
<resourceType>corpus</resourceType>
<corpusMediaType>
<corpusAudioInfo>
<mediaType>audio</mediaType>
<lingualityInfo>
<lingualityType>monolingual</lingualityType>
</lingualityInfo>
<languageInfo>
<languageId>spa</languageId>
<languageName>Spanish</languageName>
<languageVarietyInfo>
<languageVarietyType>dialect</languageVarietyType>
<languageVarietyName>Castilian</languageVarietyName>
<sizePerLanguageVariety>
<size>2</size>
<sizeUnit>gb</sizeUnit>
</sizePerLanguageVariety>
</languageVarietyInfo>
</languageInfo>
<audioSizeInfo>
<sizeInfo>
<size>no size available</size>
<sizeUnit>other</sizeUnit>
</sizeInfo>
</audioSizeInfo>
</corpusAudioInfo>
</corpusMediaType>
</corpusInfo>
</resourceComponentType>
</resourceInfo>
